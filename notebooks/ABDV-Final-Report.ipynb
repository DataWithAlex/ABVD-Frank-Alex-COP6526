{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forgotten ones:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function despawn!(agent, model)\n",
    "    # Despawn agent if unattractive steps exceed threshold\n",
    "    remove_agent!(agent, model)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent-Based Video Distortion (ABVD)\n",
    "\n",
    "![Structure of the Digital Petri Dish](../assets/notebook-images/Structure.jpg)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Our project is on a special method we developed for video distortion. Most distortion tools translate the color values of the source pixel or exploit the quirks in compression algorithms to create what's called 'data moshing'. However, independently the term data moshing evokes crowds of people pushing into one another at a punk showâ€”got us thinking if we could use agent-based modeling to make pixels mosh.\n",
    "\n",
    "To do this, we thought about an image as a petri dish, filled with all different kinds of nutrients and poisons, and the pixels as bacteria moving towards nutrients and away from poisons. Then, video frames are just a snapshot of a petri dish in time, followed by another petri dish in time.\n",
    "\n",
    "The goal, then, is to create an agent (or bacteria) that will create visually interesting effects.\n",
    "\n",
    "We've created a system where pixels behave like microscopic organisms, responding to their environment in ways that create emergent visual patterns. Each video frame becomes a moment in time of this digital ecosystem.\n",
    "\n",
    "## The Digital Petri Dish\n",
    "\n",
    "In our model, each frame is treated as a nutrient environment where:\n",
    "\n",
    "- Light areas are \"nutrients\" that attract our pixel-organisms\n",
    "- Dark areas are \"toxic\" zones that organisms try to avoid\n",
    "- Pixels can mutate their colors based on environmental pressures\n",
    "- Population dynamics emerge from birth and death cycles\n",
    "\n",
    "This biological metaphor creates organic, flowing distortions that feel more alive than traditional effects.\n",
    "\n",
    "## Loading in Necessary Packages\n",
    "\n",
    "We start by loading in all of our necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "\n",
    "required_packages = [\n",
    "    \"CSV\",\n",
    "    \"DataFrames\",\n",
    "    \"VideoIO\",\n",
    "    \"Images\",\n",
    "    \"Logging\",\n",
    "    \"Agents\",\n",
    "    \"ProgressMeter\",\n",
    "    \"FileIO\"\n",
    "]\n",
    "\n",
    "for package in required_packages\n",
    "    try\n",
    "        @eval using $(Symbol(package))\n",
    "    catch\n",
    "        println(\"Installing $package...\")\n",
    "        Pkg.add(package)\n",
    "        @eval using $(Symbol(package))\n",
    "    end\n",
    "end\n",
    "\n",
    "println(\"All required packages are installed and loaded successfully!\")\n",
    "\n",
    "using CSV\n",
    "using DataFrames\n",
    "using VideoIO\n",
    "using Images\n",
    "using Logging\n",
    "using Agents\n",
    "using ProgressMeter\n",
    "using FileIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "This code block ensures that all necessary packages are installed and loaded. It iterates over a list of required packages, attempting to load each one. If a package is not installed, it is automatically added and then loaded. This guarantees that the environment is correctly set up for the subsequent steps. The output will confirm the successful installation and loading of all packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pixel Organism\n",
    "\n",
    "Just as bacteria have specific traits that help them survive in their environment, our pixel agents have key properties:\n",
    "\n",
    "1. **HSL Color Value** (hsl_value)\n",
    "   - Like bacterial pigmentation\n",
    "   - Adapts to environmental conditions\n",
    "   - Can mutate over time\n",
    "\n",
    "2. **Active State** (active)\n",
    "   - Represents organism viability\n",
    "   - Similar to bacterial life/death states\n",
    "   - Determines if agent survives to next generation\n",
    "\n",
    "3. **Unattractive Steps** (unattractive_steps)\n",
    "   - Tracks exposure to \"toxic\" (dark) areas\n",
    "   - Similar to bacterial stress response\n",
    "   - Influences survival probability\n",
    "\n",
    "These properties work together to create organisms that can adapt and evolve within our digital petri dish, much like real bacteria adapting to their environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@agent PixelAgent GridAgent{2} begin\n",
    "    hsl_value::HSL\n",
    "    active::Bool\n",
    "    unattractive_steps::Int\n",
    "end\n",
    "\n",
    "dump(PixelAgent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "The `PixelAgent` struct is defined with three properties: `hsl_value` for color representation, `active` to indicate if the agent is currently active, and `unattractive_steps` to track exposure to undesirable areas. This structure forms the basis for agent behavior in the model. The output will show the successful definition of the `PixelAgent` struct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "In this section, we introduce utility functions that are crucial for the movement and decision-making processes of our pixel agents. These functions enable the agents to navigate their environment effectively, responding to the lightness of their surroundings and making decisions that influence their movement patterns.\n",
    "\n",
    "### Inactive Test Function\n",
    "\n",
    "The `inactive_test` function adds an element of randomness to the despawning of agents. It evaluates whether an agent should be marked inactive based on its exposure to \"toxic\" areas, represented by dark pixels. This function uses a probabilistic approach, influenced by the agent's unattractive steps and a global parameter, to determine if an agent should be removed from the simulation.\n",
    "\n",
    "### Motivated Move Function\n",
    "\n",
    "The `motivated_move` function is designed to simulate a gradient ascent behavior, where pixel agents are attracted to brighter areas of the frame. This function evaluates potential positions and selects the one with the highest lightness value, encouraging agents to move towards \"nutrient-rich\" areas.\n",
    "\n",
    "### Move Function\n",
    "\n",
    "The `move!` function governs the movement logic of each pixel agent. It incorporates randomness to prevent stagnation and uses the lightness of the current pixel to determine movement strategy. The function also checks if an agent should be marked inactive using the `inactive_test` function.\n",
    "\n",
    "![Movement Model](../assets/notebook-images/move.jpg)\n",
    "\n",
    "The graphic above illustrates the movement model. Agents are influenced by the lightness of their environment:\n",
    "\n",
    "- **Unmotivated Movement (M1):** Occurs in the lightest areas, where agents make small, random movements.\n",
    "- **Motivated Movement (M2):** In light areas, agents are more directed, seeking brighter pixels.\n",
    "- **Motivated Movement (M3):** In darker areas, agents make longer, directed movements to find brighter regions.\n",
    "\n",
    "This visual representation helps to conceptualize how agents navigate through different light zones, adapting their behavior based on environmental conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function motivated_move(current_pos, positions, hsl_matrix)\n",
    "    max_lightness = 0\n",
    "    max_position = rand(positions)\n",
    "\n",
    "    for (y, x) in positions\n",
    "        lightness = hsl_matrix[y, x].l\n",
    "        if lightness > max_lightness\n",
    "            max_lightness = lightness\n",
    "            max_position = (y, x)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return max_position\n",
    "end\n",
    "\n",
    "function move!(agent, model, hsl_matrix)\n",
    "    pixel_color = hsl_matrix[agent.pos[1], agent.pos[2]]\n",
    "\n",
    "    if inactive_test(agent.unattractive_steps, pixel_color)\n",
    "        agent.active = false\n",
    "    else\n",
    "        neighboring_positions = collect(nearby_positions(agent, model, rand(1:3)))\n",
    "\n",
    "        if rand() < 0.10\n",
    "            move_agent!(agent, rand(neighboring_positions), model)\n",
    "        elseif pixel_color.l > 0.7\n",
    "            neighboring_positions = collect(nearby_positions(agent, model, 1))\n",
    "            move_agent!(agent, rand(neighboring_positions), model)\n",
    "        elseif pixel_color.l > 0.5\n",
    "            neighboring_positions = collect(nearby_positions(agent, model, 1))\n",
    "            if !isempty(neighboring_positions)\n",
    "                new_pos = motivated_move(agent.pos, neighboring_positions, hsl_matrix)\n",
    "                move_agent!(agent, new_pos, model)\n",
    "            end\n",
    "        else\n",
    "            neighboring_positions = collect(nearby_positions(agent, model, 3))\n",
    "            if !isempty(neighboring_positions)\n",
    "                new_pos = motivated_move(agent.pos, neighboring_positions, hsl_matrix)\n",
    "                move_agent!(agent, new_pos, model)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function inactive_test(steps, hsl)\n",
    "    global parameters\n",
    "    return rand() < (steps * parameters[:unattractive_tolerance])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Explanation\n",
    "\n",
    "The `motivated_move` function iterates over all possible positions an agent can move to, evaluating the lightness of each position. It selects the position with the highest lightness, simulating a natural attraction to brighter areas.\n",
    "\n",
    "The `move!` function is more complex, incorporating several movement strategies based on the lightness of the current pixel:\n",
    "\n",
    "- **Random Movement:** Introduces a 10% chance for the agent to move randomly, which helps in exploring new areas and prevents the system from becoming static.\n",
    "- **Brightness-Based Movement:** Adjusts the movement strategy based on the lightness of the current pixel:\n",
    "  - **Very Bright Areas (L > 0.7):** Agents make small random movements, simulating a stable environment.\n",
    "  - **Moderately Bright Areas (L > 0.5):** Agents perform medium-range directed movements towards brighter pixels.\n",
    "  - **Dark Areas (L â‰¤ 0.5):** Agents engage in long-range directed movements, searching for brighter areas.\n",
    "\n",
    "The `inactive_test` function plays a crucial role in this system by determining when an agent should be marked inactive, adding a layer of realism to the simulation by mimicking the natural lifecycle of organisms. This movement logic, combined with the motivated move function, creates a dynamic and adaptive system where pixel agents continuously seek out optimal conditions, contributing to the emergent visual patterns in the video distortion process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Mutation System\n",
    "\n",
    "The `mutate_color!` function is a key component of the color mutation system, simulating how pixel agents adapt to their environment. This function uses the HSL (Hue, Saturation, Lightness) color space to allow for more natural-looking color transitions compared to RGB. The mutation system is designed to reflect different environmental pressures and includes several distinct behaviors:\n",
    "\n",
    "1. **Random Color Jumps:** A small chance of complete color randomization, simulating sudden mutations or \"quantum jumps.\"\n",
    "2. **Environmental Adaptation:** In brighter areas, colors gradually adapt to their surroundings, with hue shifting towards local pixel colors.\n",
    "3. **Dark Area Behavior:** In darker areas, colors become more unstable, with higher mutation rates and a tendency towards darker values.\n",
    "\n",
    "This function is crucial for creating the dynamic and organic visual effects seen in the video distortion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mutate_color!(agent, p_hsl)\n",
    "    global parameters\n",
    "    mutation_strength = parameters[:mutation_strength]\n",
    "    mutation_rate = parameters[:mutation_rate]\n",
    "    a_hsl = agent.hsl_value\n",
    "\n",
    "    old_hue, old_saturation, old_lightness = a_hsl.h, a_hsl.s, a_hsl.l\n",
    "\n",
    "    if rand() < parameters[:random_color_rate]\n",
    "        agent.hsl_value = HSL(rand() * 360, rand(), rand() * 0.5)\n",
    "    elseif a_hsl.l > 0.3\n",
    "        agent.hsl_value = HSL(\n",
    "            clamp(a_hsl.h + (p_hsl.h - a_hsl.h) * mutation_rate, 0, 360),\n",
    "            clamp((a_hsl.s + p_hsl.s) / 2, 0.5, 1),\n",
    "            clamp((a_hsl.l + p_hsl.l) / 2, 0, 1)\n",
    "        )\n",
    "    else\n",
    "        agent.hsl_value = HSL(\n",
    "            clamp(a_hsl.h + rand() * 360 * mutation_strength, 0, 360),\n",
    "            clamp(a_hsl.s + (rand() - 0.5) * mutation_strength, 0.5, 1),\n",
    "            clamp(a_hsl.l + (rand() - 0.5) * mutation_strength - 0.01, 0.1, 0.5)\n",
    "        )\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "The `mutate_color!` function adjusts the HSL values of an agent based on its environment. It introduces randomness to simulate sudden mutations and adapts colors gradually in brighter areas. In darker areas, the mutation strength increases, causing more significant changes. The output will confirm the successful definition of the color mutation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of the ABM Model\n",
    "\n",
    "The ABM model is initialized with the first frame of the video, setting up the environment and agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function initialize_abm_model(input_image, population_mod)\n",
    "    hsl_matrix = convert(Matrix{HSL}, input_image)\n",
    "    frame_dims = size(hsl_matrix)\n",
    "    grid_dims = (frame_dims[1], frame_dims[2])\n",
    "\n",
    "    model = ABM(PixelAgent, GridSpace(grid_dims, periodic=false))\n",
    "    global agent_id_counter = 1\n",
    "    position_to_agent = Dict()\n",
    "\n",
    "    for y in 1:population_mod:frame_dims[1], x in 1:population_mod:frame_dims[2]\n",
    "        hsl_value = hsl_matrix[y, x]\n",
    "        agent = PixelAgent(agent_id_counter, (y, x), hsl_value, true, 0)\n",
    "        add_agent!(agent, model)\n",
    "        position_to_agent[(y, x)] = agent\n",
    "        global agent_id_counter += 1\n",
    "    end\n",
    "\n",
    "    log_message(\"Model initialized with $(nagents(model)) agents.\")\n",
    "    return model, grid_dims, agent_id_counter, position_to_agent\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "The `initialize_abm_model` function converts the input image into an HSL matrix and sets up a grid space for the agents. Agents are created at specified intervals, and their initial properties are defined. This setup is crucial for simulating the behavior of pixel agents. The output will confirm the successful initialization of the ABM model with a log message indicating the number of agents created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply ABM Distortion\n",
    "\n",
    "The `apply_abm_distortion` function processes an input image by simulating the behavior of agents on a grid. Each agent represents a pixel that can move and change color based on its environment. The function updates the positions and colors of the agents, creating a distorted version of the input image. This distortion is achieved by treating the image as a dynamic environment where agents interact with their surroundings, leading to emergent visual patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function apply_abm_distortion(input_image, model, agent_id_counter)\n",
    "    hsl_matrix = convert(Matrix{HSL}, input_image)\n",
    "    frame_dims = size(hsl_matrix)\n",
    "\n",
    "    despawn_counter = 0\n",
    "    global parameters\n",
    "\n",
    "    # Initialize the distorted frame with a default color\n",
    "    distorted_frame = fill(RGB(0, 0, 0), frame_dims[1], frame_dims[2])\n",
    "\n",
    "    for agent in allagents(model)\n",
    "        old_pos = agent.pos  # Store the old position\n",
    "\n",
    "        move!(agent, model, hsl_matrix)\n",
    "        mutate_color!(agent, hsl_matrix[agent.pos[1], agent.pos[2]])\n",
    "\n",
    "        if !agent.active\n",
    "            despawn!(agent, model)\n",
    "            despawn_counter += 1\n",
    "        end\n",
    "\n",
    "        if hsl_matrix[agent.pos[1], agent.pos[2]].l < parameters[:unattractive_threshold]\n",
    "            agent.unattractive_steps += 1\n",
    "        else\n",
    "            agent.unattractive_steps = 0\n",
    "        end\n",
    "\n",
    "        # Update the current position with the agent's color\n",
    "        color = RGB(agent.hsl_value)\n",
    "        for i in 0:parameters[:pixel_size]-1\n",
    "            for j in 0:parameters[:pixel_size]-1\n",
    "                y = clamp(agent.pos[1] + i, 1, frame_dims[1])\n",
    "                x = clamp(agent.pos[2] + j, 1, frame_dims[2])\n",
    "                distorted_frame[y, x] = color\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # Clear the old position if trailing is false\n",
    "        if !parameters[:trailing] && old_pos != agent.pos\n",
    "            for i in 0:parameters[:pixel_size]-1\n",
    "                for j in 0:parameters[:pixel_size]-1\n",
    "                    y = clamp(old_pos[1] + i, 1, frame_dims[1])\n",
    "                    x = clamp(old_pos[2] + j, 1, frame_dims[2])\n",
    "                    distorted_frame[y, x] = RGB(0, 0, 0)  # Clear the trail\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return colorview(RGB, distorted_frame)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "The `apply_abm_distortion` function operates as follows:\n",
    "\n",
    "1. **HSL Conversion**: The input image is converted into an HSL matrix, which allows for more natural manipulation of color properties.\n",
    "\n",
    "2. **Frame Initialization**: A new frame is initialized with a default black color, which will be updated as agents move and change color.\n",
    "\n",
    "3. **Agent Processing**: Each agent in the model is processed:\n",
    "   - **Movement**: The agent's position is updated based on its environment using the `move!` function.\n",
    "   - **Color Mutation**: The agent's color is potentially mutated based on the lightness of its current position using the `mutate_color!` function.\n",
    "   - **Despawn Check**: If an agent becomes inactive, it is removed from the model.\n",
    "   - **Unattractive Steps**: The agent's exposure to \"toxic\" areas (dark pixels) is tracked, influencing its survival.\n",
    "\n",
    "4. **Color Update**: The agent's new position is updated in the distorted frame with its current color. If the `trailing` parameter is false, the agent's previous position is cleared to prevent trails.\n",
    "\n",
    "5. **Return**: The function returns a color view of the distorted frame, which represents the processed image with applied distortions.\n",
    "\n",
    "This function is central to creating the dynamic and organic visual effects characteristic of the ABVD model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of ABM Distortion to Video\n",
    "\n",
    "The ABM distortion is applied to each video frame, processing the frames through the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function apply_abm_distortion_to_video(input_video_path; parameters)\n",
    "    frame_folder = \"../outputs/frames_temp/\"\n",
    "    processed_folder = \"../outputs/processed_frames_temp/\"\n",
    "\n",
    "    isdir(frame_folder) || mkpath(frame_folder)\n",
    "    isdir(processed_folder) || mkpath(processed_folder)\n",
    "\n",
    "    log_message(\"Processing video $input_video_path\")\n",
    "\n",
    "    video = VideoIO.openvideo(input_video_path)\n",
    "    frame_index = 1\n",
    "    while !eof(video)\n",
    "        frame = read(video)\n",
    "        save(\"$frame_folder/frame_$frame_index.png\", frame)\n",
    "        frame_index += 1\n",
    "    end\n",
    "    close(video)\n",
    "    log_message(\"Extracted $(frame_index - 1) frames from $input_video_path.\")\n",
    "\n",
    "    first_frame = load(\"$frame_folder/frame_1.png\")\n",
    "    global model, grid_dims, agent_id_counter, position_to_agent = initialize_abm_model(first_frame, parameters[:pixel_pop_mod])\n",
    "\n",
    "    # Create a progress bar\n",
    "    progress = Progress(frame_index - 1, 1, \"Processing frames\")\n",
    "\n",
    "    for i in 1:frame_index - 1\n",
    "        original_frame = load(\"$frame_folder/frame_$i.png\")\n",
    "        distorted_frame = apply_abm_distortion(original_frame, model, agent_id_counter)\n",
    "        save(\"$processed_folder/frame_$i.png\", distorted_frame)\n",
    "        \n",
    "        # Update progress bar\n",
    "        next!(progress)\n",
    "        \n",
    "        # Log every 10 frames\n",
    "        if i % 10 == 0\n",
    "            flush(stdout)  # Ensure the output is immediately displayed\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Log a summary of the processing\n",
    "    log_message(\"Completed processing of $frame_index frames.\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "The `apply_abm_distortion_to_video` function extracts frames from the input video, applies the ABM distortion to each frame, and saves the processed frames. It initializes the model with the first frame and processes each subsequent frame through the simulation, updating agent positions and colors. The output will include log messages indicating the progress of frame extraction and processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation of Video from Frames\n",
    "\n",
    "The processed frames are compiled back into a video, completing the distortion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compile_video_from_frames(input_folder, output_video_path, fps=30)\n",
    "    println(\"Starting video compilation...\")\n",
    "    python_path = \"/Users/alexsciuto/Library/Mobile Documents/com~apple~CloudDocs/DataWithAlex/ABM-Project-Frank-Alex-COP6526/ABVD-Frank-Alex-COP6526/venv/bin/python\"\n",
    "    script_path = \"../video-compiler.py\"  # Adjusted path to the script\n",
    "    try\n",
    "        # Use the correct path for the processed frames\n",
    "        command = `$python_path $script_path ../outputs/processed_frames_temp $output_video_path --fps $fps`\n",
    "        \n",
    "        println(\"Running Python script to compile video...\")\n",
    "        println(\"Command: $command\")\n",
    "\n",
    "        output = read(command, String)\n",
    "        println(\"Python script output:\\n$output\")\n",
    "        log_message(\"Python script output:\\n$output\")\n",
    "\n",
    "        log_message(\"Video saved to $output_video_path.\")\n",
    "        println(\"Video saved to $output_video_path.\")\n",
    "    catch e\n",
    "        log_message(\"Error executing Python script: $e\")\n",
    "        println(\"Error executing Python script: $e\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "The `compile_video_from_frames` function uses a Python script to compile the processed frames into a final video. It logs the process and handles any errors that occur. This step completes the video distortion pipeline, resulting in a visually compelling video that showcases the effects of the ABM model. The output will include log messages confirming the successful compilation of the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Example\n",
    "\n",
    "In this section, we will demonstrate the application of the ABVD model using a sample video. We will set parameters optimized for speed and detail, process the video frames, and compile the final output video.\n",
    "\n",
    "### Parameters and Paths\n",
    "\n",
    "We define the parameters and paths necessary for processing the video. These parameters control the behavior of the pixel agents and the characteristics of the output video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters optimized for speed\n",
    "global parameters = Dict(\n",
    "    :pixel_size => 8,          # Smaller pixel size for more detail\n",
    "    :pixel_pop_mod => 10,      # More initial agents\n",
    "    :sim_per_frames => 1,      # Keep as is\n",
    "    :mutation_strength => 0.6, # Increase for more color variation\n",
    "    :unattractive_tolerance => 0.02,  # Lower tolerance to reduce despawning\n",
    "    :unattractive_threshold => 0.2,   # Lower threshold to keep agents active longer\n",
    "    :mutation_rate => 0.5,     # Increase for more color change\n",
    "    :random_color_rate => 0.1, # Increase for more random color generation\n",
    "    :trailing => false         # Keep as is\n",
    ")\n",
    "\n",
    "# Define paths relative to the notebook's location\n",
    "input_video_path = \"../inputs/eye.mp4\"\n",
    "\n",
    "# Extract the base name of the input video file\n",
    "input_base_name = splitext(basename(input_video_path))[1]\n",
    "\n",
    "# Create a string representation of all parameters\n",
    "param_str = \"px$(parameters[:pixel_size])_pop$(parameters[:pixel_pop_mod])_sim$(parameters[:sim_per_frames])_\" *\n",
    "            \"mutStr$(parameters[:mutation_strength])_unTol$(parameters[:unattractive_tolerance])_\" *\n",
    "            \"unThr$(parameters[:unattractive_threshold])_mutRate$(parameters[:mutation_rate])_\" *\n",
    "            \"randColRate$(parameters[:random_color_rate])\"\n",
    "\n",
    "# Construct the output video path\n",
    "output_video_path = \"../outputs/$(input_base_name)_$(param_str).mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing and Compiling the Video\n",
    "\n",
    "We apply the ABVD model to the video frames and compile the processed frames into a final video. This process involves extracting frames, applying agent-based distortion, and using a Python script to compile the frames into a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define logging function with log levels\n",
    "function log_message(msg, level=\"INFO\")\n",
    "    if level == \"ERROR\" || level == \"WARNING\" || level == \"INFO\"\n",
    "        println(\"[$level] $msg\")\n",
    "    end\n",
    "end\n",
    "\n",
    "# Process frames\n",
    "apply_abm_distortion_to_video(input_video_path; parameters)\n",
    "\n",
    "# Use the correct path for the processed frames\n",
    "compile_video_from_frames(\"../outputs/processed_frames_temp\", output_video_path, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output\n",
    "\n",
    "The following output is expected when running the example. It includes log messages indicating the progress of video processing and compilation, as well as the final confirmation of the video being saved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the implementation of the Agent-Based Video Distortion (ABVD) model, showcasing how agent-based modeling can be applied to video processing to create dynamic and organic visual effects. By treating each video frame as a digital petri dish, we simulate pixel agents that respond to their environment, resulting in emergent visual patterns that are both complex and aesthetically intriguing.\n",
    "\n",
    "The detailed markdown explanations throughout the notebook provide a comprehensive understanding of each step, from setting up the environment and defining pixel agents to processing video frames and compiling the final output. This ensures that the notebook is not only executable but also serves as an educational resource for understanding the principles and applications of agent-based modeling in digital media.\n",
    "\n",
    "By experimenting with different parameters and input videos, users can explore a wide range of visual effects, further demonstrating the versatility and creative potential of the ABVD model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters optimized for speed\n",
    "global parameters = Dict(\n",
    "    :pixel_size => 8,          # Smaller pixel size for more detail\n",
    "    :pixel_pop_mod => 10,      # More initial agents\n",
    "    :sim_per_frames => 1,      # Keep as is\n",
    "    :mutation_strength => 0.6, # Increase for more color variation\n",
    "    :unattractive_tolerance => 0.02,  # Lower tolerance to reduce despawning\n",
    "    :unattractive_threshold => 0.2,   # Lower threshold to keep agents active longer\n",
    "    :mutation_rate => 0.5,     # Increase for more color change\n",
    "    :random_color_rate => 0.1, # Increase for more random color generation\n",
    "    :trailing => true          # Keep as is\n",
    ")\n",
    "\n",
    "# Define paths relative to the notebook's location\n",
    "input_video_path = \"../inputs/eye.mp4\"\n",
    "\n",
    "# Extract the base name of the input video file\n",
    "input_base_name = splitext(basename(input_video_path))[1]\n",
    "\n",
    "# Create a string representation of all parameters\n",
    "param_str = \"px$(parameters[:pixel_size])_pop$(parameters[:pixel_pop_mod])_sim$(parameters[:sim_per_frames])_\" *\n",
    "            \"mutStr$(parameters[:mutation_strength])_unTol$(parameters[:unattractive_tolerance])_\" *\n",
    "            \"unThr$(parameters[:unattractive_threshold])_mutRate$(parameters[:mutation_rate])_\" *\n",
    "            \"randColRate$(parameters[:random_color_rate])_trailing$(parameters[:trailing])\"\n",
    "\n",
    "# Construct the output video path\n",
    "output_video_path = \"../outputs/$(input_base_name)_$(param_str).mp4\"\n",
    "\n",
    "# Process frames\n",
    "apply_abm_distortion_to_video(input_video_path; parameters)\n",
    "\n",
    "# Use the correct path for the processed frames\n",
    "compile_video_from_frames(\"../outputs/processed_frames_temp\", output_video_path, 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
